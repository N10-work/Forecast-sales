{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Deployment Environment\n",
    "Create an S3 bucket for the build, deploy the Lambda binaries and CloudFormation template, and run CloudFormation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Required] \n",
    "For running Cloud Formation, some roles below are needed:  \n",
    "- AmazonS3FullAccess or ListBucket/GetObject/DeleteObject/PutObject  \n",
    "- AWSLambdaFullAccess  \n",
    "- IAMFullAccess  \n",
    "- AWSCloudTrailFullAccess  \n",
    "- CloudWatchLogsFullAccess  \n",
    "- AWSStepFunctionsFullAccess  \n",
    "- AmazonSageMakerFullAccess  \n",
    "- AWSCloudFormationFullAccess  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create S3 bucket  \n",
    "Create an S3 bucket to store the Lambda binary file and the Cloud Formation template file to be used for environment preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "region = session.region_name\n",
    "account_id = session.client('sts').get_caller_identity().get('Account')\n",
    "bucket_name = f'workshop-timeseries-retail-{account_id}-deploy'\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'workshop-timeseries-retail-673990568411-deploy'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0SRC9CSTMMPXCP51',\n",
       "  'HostId': 'TVQ10O5qJZI8OlB/28vESb3t9p5Ux3eRO5WWJn+4eIqLwSk3Ug5slpoQ4c4C1frAwr7c2OljNyk=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'TVQ10O5qJZI8OlB/28vESb3t9p5Ux3eRO5WWJn+4eIqLwSk3Ug5slpoQ4c4C1frAwr7c2OljNyk=',\n",
       "   'x-amz-request-id': '0SRC9CSTMMPXCP51',\n",
       "   'date': 'Thu, 18 Feb 2021 23:27:53 GMT',\n",
       "   'location': 'http://workshop-timeseries-retail-673990568411-deploy.s3.amazonaws.com/',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Location': 'http://workshop-timeseries-retail-673990568411-deploy.s3.amazonaws.com/'}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "s3.create_bucket(Bucket=bucket_name,\n",
    "                CreateBucketConfiguration={'LocationConstraint':region}\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put Lambda zip files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lambdas_deploy\\createdataset.zip\n",
      "lambdas_deploy\\createdatasetgroup.zip\n",
      "lambdas_deploy\\createdatasetimport.zip\n",
      "lambdas_deploy\\createforecast.zip\n",
      "lambdas_deploy\\createforecastexportjob.zip\n",
      "lambdas_deploy\\createpredictor.zip\n",
      "lambdas_deploy\\getstatusforecast.zip\n",
      "lambdas_deploy\\getstatusforecastexportjob.zip\n",
      "lambdas_deploy\\getstatusimport.zip\n",
      "lambdas_deploy\\getstatuspredictor.zip\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob(\"lambdas_deploy/*\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "    s3.upload_file(file, bucket_name, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CloudFormation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file('cfn_template.yaml', bucket_name, 'cfn_template.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = boto3.client('cloudformation')\n",
    "res = cf.create_stack(\n",
    "    StackName=('workshop-timeseries-retail'),\n",
    "    TemplateURL=f'https://workshop-timeseries-retail-{account_id}-deploy.s3.amazonaws.com/cfn_template.yaml',\n",
    "    Parameters=[\n",
    "        {\n",
    "            'ParameterKey': 'BucketName',\n",
    "            'ParameterValue': bucket_name\n",
    "        },\n",
    "        {\n",
    "            'ParameterKey': 'Account',\n",
    "            'ParameterValue': account_id\n",
    "        },\n",
    "    ],\n",
    "    Capabilities=[\n",
    "        'CAPABILITY_IAM',\n",
    "        'CAPABILITY_AUTO_EXPAND',\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "Wait for CloudFormation to complete. When it is complete, switch to the sagemaker notebook instance named workshop-timeseries-retail-ForecastNotebook created by the Cloud Formation and run 1_build_statemachine.ipynb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}